<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>REINFORCEMENT LEARNING</title>
    <style>
        body {
            font-family: Arial, sans-serif;
        }

        .course-title {
            font-size: 24px;
            font-weight: bold;
        }

        .module-title {
            font-size: 20px;
            margin-top: 10px;
            color: #333;
        }

        .topic-title {
            font-size: 16px;
            margin-left: 20px;
        }
    </style>
</head>

<body>
    <div class="course-title">REINFORCEMENT LEARNING</div>

    
    <div class="module-title">
        Module: Review Of Probability Concepts (Duration: 8 hours)
    </div>

    <ul>
        
        <li class="topic-title">
            <a href="Review Of Probability Concepts/1.1.html">
                Topic 1.1: Axioms of probability, concepts of random variables
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Review Of Probability Concepts/1.2.html">
                Topic 1.2: Probability mass function
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Review Of Probability Concepts/1.3.html">
                Topic 1.3: Probability density function
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Review Of Probability Concepts/1.4.html">
                Topic 1.4: Cumulative density functions
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Review Of Probability Concepts/1.5.html">
                Topic 1.5: Expectation of random variables
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Review Of Probability Concepts/1.6.html">
                Topic 1.6: Joint and multiple random variables
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Review Of Probability Concepts/1.7.html">
                Topic 1.7: Conditional and marginal distributions
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Review Of Probability Concepts/1.8.html">
                Topic 1.8: Correlation and independence
            </a>
        </li>
        
    </ul>
    
    <div class="module-title">
        Module: Markov Decision Process (Duration: 8 hours)
    </div>

    <ul>
        
        <li class="topic-title">
            <a href="Markov Decision Process/2.1.html">
                Topic 2.1: Introduction to Reinforcement Learning(RL) terminology - Examples of RL, Elements of RL, Limitations and Scope of RL
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Markov Decision Process/2.2.html">
                Topic 2.2: Finite Markov Decision Processes
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Markov Decision Process/2.3.html">
                Topic 2.3: The Agent–Environment Interface
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Markov Decision Process/2.4.html">
                Topic 2.4: Goals and Rewards
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Markov Decision Process/2.5.html">
                Topic 2.5: Returns and Episodes
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Markov Decision Process/2.6.html">
                Topic 2.6: Policies and Value Functions
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Markov Decision Process/2.7.html">
                Topic 2.7: Optimal Policies and Optimal Value Functions
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Markov Decision Process/2.8.html">
                Topic 2.8: Optimal Policies and Optimal Value Functions
            </a>
        </li>
        
    </ul>
    
    <div class="module-title">
        Module: Prediction And Control (Duration: 9 hours)
    </div>

    <ul>
        
        <li class="topic-title">
            <a href="Prediction And Control/3.1.html">
                Topic 3.1: Policy Evaluation (Prediction)
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Prediction And Control/3.2.html">
                Topic 3.2: Policy Improvement
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Prediction And Control/3.3.html">
                Topic 3.3: Policy Iteration, Value Iteration
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Prediction And Control/3.4.html">
                Topic 3.4: Monte Carlo Prediction
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Prediction And Control/3.5.html">
                Topic 3.5: Monte Carlo Estimation of Action Values
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Prediction And Control/3.6.html">
                Topic 3.6: Monte Carlo Control, Monte Carlo Control without Exploring Starts
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Prediction And Control/3.7.html">
                Topic 3.7: Off-policy Prediction via Importance Sampling
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Prediction And Control/3.8.html">
                Topic 3.8: Incremental Implementation
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Prediction And Control/3.9.html">
                Topic 3.9: Off-policy Monte Carlo Control
            </a>
        </li>
        
    </ul>
    
    <div class="module-title">
        Module: Temporal-Difference( Td) Methods (Duration: 8 hours)
    </div>

    <ul>
        
        <li class="topic-title">
            <a href="Temporal-Difference( Td) Methods/4.1.html">
                Topic 4.1: TD Prediction, Advantages of TD Prediction Methods
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Temporal-Difference( Td) Methods/4.2.html">
                Topic 4.2: Optimality of TD(0)
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Temporal-Difference( Td) Methods/4.3.html">
                Topic 4.3: Sarsa: On-policy TD Control
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Temporal-Difference( Td) Methods/4.4.html">
                Topic 4.4: Q-learning: Off-policy TD Control
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Temporal-Difference( Td) Methods/4.5.html">
                Topic 4.5: Expected Sarsa
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Temporal-Difference( Td) Methods/4.6.html">
                Topic 4.6: n-step TD Prediction, n-step Sarsa
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Temporal-Difference( Td) Methods/4.7.html">
                Topic 4.7: n-step Off-policy Learning
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Temporal-Difference( Td) Methods/4.8.html">
                Topic 4.8: Off-policy Learning Without Importance Sampling: The n-step Tree Backup Algorithm
            </a>
        </li>
        
    </ul>
    
    <div class="module-title">
        Module: Function Approximation Method (Duration: 9 hours)
    </div>

    <ul>
        
        <li class="topic-title">
            <a href="Function Approximation Method/5.1.html">
                Topic 5.1: Value-function Approximation
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Function Approximation Method/5.2.html">
                Topic 5.2: The Prediction Objective
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Function Approximation Method/5.3.html">
                Topic 5.3: Stochastic-gradient Methods
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Function Approximation Method/5.4.html">
                Topic 5.4: Linear Methods
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Function Approximation Method/5.5.html">
                Topic 5.5: The Lambda-return , TD(Lambda)
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Function Approximation Method/5.6.html">
                Topic 5.6: n-step Truncated Lambda-return Methods, Sarsa(Lambda)
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Function Approximation Method/5.7.html">
                Topic 5.7: Policy Approximation and its Advantages
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Function Approximation Method/5.8.html">
                Topic 5.8: The Policy Gradient Theorem, REINFORCE: Monte Carlo Policy Gradient
            </a>
        </li>
        
        <li class="topic-title">
            <a href="Function Approximation Method/5.9.html">
                Topic 5.9: REINFORCE with Baseline, Actor–Critic Methods
            </a>
        </li>
        
    </ul>
    
</body>

</html>